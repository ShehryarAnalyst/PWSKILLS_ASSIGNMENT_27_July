{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37ef8e86",
   "metadata": {},
   "source": [
    "## Assignment Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7031e392",
   "metadata": {},
   "source": [
    "## Understanding Pooling and Padding in CNN\n",
    "\n",
    "__Q: Describe the purpose and benefits of pooling in CNN.__\n",
    "\n",
    "__A:__ Pooling in Convolutional Neural Networks (CNNs) is a technique used to downsample the spatial dimensions of feature maps, reducing computational complexity and memory requirements. It helps retain important information while discarding less relevant details. Pooling enhances translation invariance and reduces overfitting by providing a generalized representation of features.\n",
    "\n",
    "__Q: Explain the difference between Max pooling and Average pooling.__\n",
    "\n",
    "__A:__ Max pooling and Average pooling are common pooling methods. Max pooling retains the maximum value within a pooling window, emphasizing the most prominent feature. Average pooling calculates the average value in the window, providing a smoother representation of features. Max pooling tends to preserve sharper features, while Average pooling can be less sensitive to small variations.\n",
    "\n",
    "__Q: Discuss the concept of padding in CNN and its significance.__\n",
    "\n",
    "__A:__ Padding involves adding additional pixels to the input image before applying convolutions. It addresses the issue of information loss at the edges of feature maps caused by convolution operations. Padding ensures that the spatial dimensions are preserved, enhances the ability to capture features at the borders, and contributes to the network's stability during training.\n",
    "\n",
    "__Q:__ Compare and contrast zero-padding and valid-padding in terms of their effects on the output feature map size.\n",
    "A: Zero-padding involves adding zeros around the input image, which maintains the output size after convolution. Valid-padding, on the other hand, uses only valid portions of the input, resulting in a smaller output size. Zero-padding is useful when maintaining the spatial dimensions is crucial, while valid-padding reduces the feature map size and can lead to decreased information retention.\n",
    "\n",
    "### Exploring LeNet\n",
    "\n",
    "__Q: Provide a concise overview of the LeNet-5 architecture.__\n",
    "A: LeNet-5 is an early convolutional neural network designed for handwritten digit recognition. It comprises layers of convolution, pooling, and fully connected layers. The architecture consists of input convolutions, subsampling layers, fully connected layers, and a softmax output layer.\n",
    "\n",
    "__Q:Describe the key components of LeNet-5 and their respective purposes.__\n",
    "\n",
    "A: LeNet-5's key components include convolutional layers for feature extraction, subsampling (pooling) layers for downsampling, and fully connected layers for classification. The architecture's gradual reduction in spatial dimensions through convolutions and pooling helps capture hierarchical features.\n",
    "\n",
    "__Q:Discuss the advantages and limitations of LeNet-5 in the context of image classification tasks.__\n",
    "A: Advantages include simplicity, effectiveness on small-sized images, and early recognition of handwritten digits. However, LeNet-5's limitations arise from its architecture's simplicity, making it less effective on complex tasks and large datasets compared to modern architectures.\n",
    "\n",
    "__Q: Implement LeNet-5 using a deep learning framework of your choice and train it on a publicly available dataset (e.g., MNIST). Evaluate its performance and provide insights.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d13a219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 14s 15ms/step - loss: 0.2379 - accuracy: 0.9315 - val_loss: 0.0920 - val_accuracy: 0.9743\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 9s 11ms/step - loss: 0.0785 - accuracy: 0.9757 - val_loss: 0.0592 - val_accuracy: 0.9825\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 19s 23ms/step - loss: 0.0589 - accuracy: 0.9816 - val_loss: 0.0431 - val_accuracy: 0.9882\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 22s 27ms/step - loss: 0.0475 - accuracy: 0.9847 - val_loss: 0.0440 - val_accuracy: 0.9878\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 10s 11ms/step - loss: 0.0382 - accuracy: 0.9877 - val_loss: 0.0429 - val_accuracy: 0.9887\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0358 - accuracy: 0.9875\n",
      "Test accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32')\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32')\n",
    "\n",
    "# Build the LeNet-5 model\n",
    "model = Sequential([\n",
    "    Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(120, activation='relu'),\n",
    "    Dense(84, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735dce84",
   "metadata": {},
   "source": [
    "### Analyzing AlexNet\n",
    "\n",
    "__Q: Present an overview of the AlexNet architecture.__\n",
    "\n",
    "__A:__ AlexNet is a pioneering deep convolutional neural network designed for the ImageNet Large Scale Visual Recognition Challenge. It features multiple convolutional layers, pooling layers, and fully connected layers. AlexNet's innovative architecture contributed to its breakthrough performance.\n",
    "\n",
    "__Q: Explain the architectural innovations introduced in AlexNet that contributed to its remarkable performance.__\n",
    "\n",
    "__A:__ AlexNet introduced the concept of stacking multiple convolutional and pooling layers, utilizing ReLU activations for faster training and overcoming the vanishing gradient problem. Additionally, it employed data augmentation and dropout to prevent overfitting.\n",
    "\n",
    "__Q: Discuss the role of convolutional layers, pooling layers, and fully connected layers in AlexNet.__\n",
    "\n",
    "__A:__ Convolutional layers extract features hierarchically, pooling layers downsample spatial dimensions, and fully connected layers provide classification based on high-level features. This layered architecture enables AlexNet to capture intricate features and patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed78a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda Setup\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "Downloading Oxford 17 category Flower Dataset, Please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0% 60276736 / 60270631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully downloaded 17flowers.tgz 60270631 bytes.\n",
      "File Extracted\n",
      "Starting to parse images...\n",
      "Parsing Done!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "# Get Data\n",
    "import tflearn.datasets.oxflower17 as oxflower17\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "x, y = oxflower17.load_data()\n",
    "\n",
    "x_train = x.astype('float32') / 255.0\n",
    "y_train = to_categorical(y, num_classes=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff9f7778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1360, 224, 224, 3)\n",
      "(1360, 17)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7e7b5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda Setup\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:562: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_17 (Conv2D)          (None, 54, 54, 96)        34944     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 54, 54, 96)        0         \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 26, 26, 96)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 26, 26, 96)       384       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 26, 26, 256)       614656    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 26, 26, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 12, 12, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 12, 12, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 10, 10, 384)       885120    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 10, 10, 384)       0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 10, 10, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 8, 8, 384)         1327488   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 8, 8, 384)         0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 8, 8, 384)        1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 6, 6, 256)         884992    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 2, 2, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 2, 2, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 4096)              4198400   \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 4096)             16384     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 4096)             16384     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 17)                69649     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 17)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,834,833\n",
      "Trainable params: 24,815,697\n",
      "Non-trainable params: 19,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation before passing it to the next layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# Passing it to a dense layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# 1st Dense Layer\n",
    "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Dense Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(17))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fd8a4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9859b1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1088 samples, validate on 272 samples\n",
      "Epoch 1/5\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 3.3829 - acc: 0.2601"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda Setup\\lib\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088/1088 [==============================] - 82s 75ms/sample - loss: 3.3829 - acc: 0.2601 - val_loss: 3.0117 - val_acc: 0.0588\n",
      "Epoch 2/5\n",
      "1088/1088 [==============================] - 79s 72ms/sample - loss: 2.2595 - acc: 0.4164 - val_loss: 3.7907 - val_acc: 0.0368\n",
      "Epoch 3/5\n",
      "1088/1088 [==============================] - 91s 84ms/sample - loss: 1.8215 - acc: 0.5092 - val_loss: 5.1557 - val_acc: 0.0588\n",
      "Epoch 4/5\n",
      "1088/1088 [==============================] - 87s 80ms/sample - loss: 1.4633 - acc: 0.5515 - val_loss: 6.2811 - val_acc: 0.0588\n",
      "Epoch 5/5\n",
      "1088/1088 [==============================] - 81s 74ms/sample - loss: 1.1620 - acc: 0.6415 - val_loss: 5.7780 - val_acc: 0.0588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23d5138d750>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=1,validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b250ffbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
